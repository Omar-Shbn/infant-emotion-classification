{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a11cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import random, math\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision.transforms import InterpolationMode as IM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85595453",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLITS_DIR = Path(r\"Data/data_emotions/splits\")       # folder with train.csv\n",
    "TRAIN_CSV  = SPLITS_DIR / \"train.csv\"\n",
    "\n",
    "# Where to save augmented images + CSVs\n",
    "OUT_DIR    = Path(r\"./data_emotions/augmented\")\n",
    "AUG_IMG_DIR = OUT_DIR / \"train_images_aug\"\n",
    "AUG_IMG_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64e7cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "# Brightness/Contrast factors for (darker, original, brighter)\n",
    "BC_OPTIONS = {\n",
    "    \"dark\":   (0.8, 0.8),\n",
    "    \"orig\":   (1.0, 1.0),\n",
    "    \"bright\": (1.2, 1.2),\n",
    "}\n",
    "ROTATIONS = [-15, 0, 15]          # degrees\n",
    "FLIPS     = [False, True]         # original, flipped\n",
    "CROPS_PER_COMBO = 4               # random crops per (rotation, flip, brightness/contrast)\n",
    "# =========================\n",
    "\n",
    "random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1122252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_crop_to(img: Image.Image, target_w: int, target_h: int) -> Image.Image:\n",
    "    \"\"\"Center-crop (or pad via resize+crop) to target size.\"\"\"\n",
    "    w, h = img.size\n",
    "    # If rotation expand=True, the image got bigger; center-crop back\n",
    "    left = max((w - target_w) // 2, 0)\n",
    "    top  = max((h - target_h) // 2, 0)\n",
    "    right = left + min(target_w, w)\n",
    "    bottom = top + min(target_h, h)\n",
    "    img = img.crop((left, top, right, bottom))\n",
    "    if img.size != (target_w, target_h):\n",
    "        img = img.resize((target_w, target_h), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "def random_crop_resized(img: Image.Image, out_w: int, out_h: int) -> Image.Image:\n",
    "    \"\"\"Random crop a region (80â€“100% of min side) and resize back to (out_w, out_h).\"\"\"\n",
    "    w, h = img.size\n",
    "    min_side = min(w, h)\n",
    "    # choose crop size between 80% and 100% of min side\n",
    "    side = int(random.uniform(0.80, 1.00) * min_side)\n",
    "    side = max(1, min(side, min_side))\n",
    "    # random top-left ensuring inside bounds\n",
    "    if w == side:\n",
    "        left = 0\n",
    "    else:\n",
    "        left = random.randint(0, w - side)\n",
    "    if h == side:\n",
    "        top = 0\n",
    "    else:\n",
    "        top = random.randint(0, h - side)\n",
    "    crop = img.crop((left, top, left + side, top + side))\n",
    "    return crop.resize((out_w, out_h), Image.BILINEAR)\n",
    "\n",
    "def apply_bc(img: Image.Image, b_factor: float, c_factor: float) -> Image.Image:\n",
    "    # torchvision F works on tensors, so use PIL adjustments here:\n",
    "    # We'll convert via torchvision functional which supports PIL directly.\n",
    "    img = F.adjust_brightness(img, b_factor)\n",
    "    img = F.adjust_contrast(img, c_factor)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ef2716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10/79 images...\n",
      "Processed 20/79 images...\n",
      "Processed 30/79 images...\n",
      "Processed 40/79 images...\n",
      "Processed 50/79 images...\n",
      "Processed 60/79 images...\n",
      "Processed 70/79 images...\n",
      "\n",
      "Augmented images saved to: data_emotions\\augmented\\train_images_aug\n",
      "Augmented CSV:           data_emotions\\augmented\\train_aug.csv  (5688 rows)\n",
      "Combined CSV:            data_emotions\\augmented\\train_with_aug.csv  (5767 rows)\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = pd.read_csv(TRAIN_CSV)\n",
    "    assert {\"resolved_path\",\"image\",\"label\",\"label_norm\",\"label_id\"}.issubset(df.columns), \\\n",
    "        \"train.csv must have columns: resolved_path,image,label,label_norm,label_id\"\n",
    "\n",
    "    aug_rows = []  # rows for train_aug.csv\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        src_path = Path(row[\"resolved_path\"])\n",
    "        try:\n",
    "            img = Image.open(src_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping unreadable image: {src_path} ({e})\")\n",
    "            continue\n",
    "\n",
    "        orig_w, orig_h = img.size\n",
    "        stem, ext = src_path.stem, src_path.suffix.lower() or \".jpg\"\n",
    "\n",
    "        for deg in ROTATIONS:\n",
    "            # rotate with expand to avoid corner cut, then center-crop to original size\n",
    "            rotated = F.rotate(img, angle=deg, interpolation=IM.BILINEAR, expand=True, fill=0)\n",
    "            rotated = center_crop_to(rotated, orig_w, orig_h)\n",
    "\n",
    "            for flip in FLIPS:\n",
    "                x = F.hflip(rotated) if flip else rotated\n",
    "\n",
    "                for bc_name, (b_fac, c_fac) in BC_OPTIONS.items():\n",
    "                    x_bc = apply_bc(x, b_fac, c_fac)\n",
    "\n",
    "                    for k in range(CROPS_PER_COMBO):\n",
    "                        x_final = random_crop_resized(x_bc, orig_w, orig_h)\n",
    "\n",
    "                        # build unique filename\n",
    "                        flip_tag = \"hf\" if flip else \"orig\"\n",
    "                        fname = f\"{stem}_r{deg}_{flip_tag}_bc{bc_name}_c{k}{ext}\"\n",
    "                        out_path = AUG_IMG_DIR / fname\n",
    "                        # avoid collisions\n",
    "                        i = 1\n",
    "                        while out_path.exists():\n",
    "                            out_path = AUG_IMG_DIR / f\"{stem}_r{deg}_{flip_tag}_bc{bc_name}_c{k}_{i}{ext}\"\n",
    "                            i += 1\n",
    "\n",
    "                        x_final.save(out_path, quality=95)\n",
    "\n",
    "                        aug_rows.append({\n",
    "                            \"resolved_path\": str(out_path.resolve()),\n",
    "                            \"image\": out_path.name,\n",
    "                            \"label\": row[\"label\"],\n",
    "                            \"label_norm\": row[\"label_norm\"],\n",
    "                            \"label_id\": int(row[\"label_id\"]),\n",
    "                        })\n",
    "\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            print(f\"Processed {idx+1}/{len(df)} images...\")\n",
    "\n",
    "    # Save CSVs\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    aug_df = pd.DataFrame(aug_rows, columns=[\"resolved_path\",\"image\",\"label\",\"label_norm\",\"label_id\"])\n",
    "    aug_df.to_csv(OUT_DIR / \"train_aug.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # Combined (original + augmented)\n",
    "    combined = pd.concat([df[[\"resolved_path\",\"image\",\"label\",\"label_norm\",\"label_id\"]]], ignore_index=True)\n",
    "    combined = pd.concat([combined, aug_df], ignore_index=True)\n",
    "    combined.to_csv(OUT_DIR / \"train_with_aug.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    print(f\"\\nAugmented images saved to: {AUG_IMG_DIR}\")\n",
    "    print(f\"Augmented CSV:           {OUT_DIR/'train_aug.csv'}  ({len(aug_df)} rows)\")\n",
    "    print(f\"Combined CSV:            {OUT_DIR/'train_with_aug.csv'}  ({len(combined)} rows)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
